{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **FIAP Pós-Tech - IA para Devs**"
      ],
      "metadata": {
        "id": "EEfXkOdymsPV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GRUPO 12 - IA para Devs\n",
        "\n",
        "```\n",
        "# Nomes\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "LLbM9q13mwqj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HACKATHON - DETECÇÃO DE MATERIAIS CORTANTES\n",
        "\n",
        "A FIAP VisionGuard, empresa de monitoramento de câmeras de segurança, está\n",
        "analisando a viabilidade de uma nova funcionalidade para otimizar o seu software.\n",
        "\n",
        "O objetivo da empresa é usar de novas tecnologias para identificar situações atípicas e\n",
        "que possam colocar em risco a segurança de estabelecimentos e comércios que utilizam\n",
        "suas câmeras.\n",
        "\n",
        "Um dos principais desafios da empresa é utilizar Inteligência Artificial para identificar\n",
        "objetos cortantes (facas, tesouras e similares) e emitir alertas para a central de\n",
        "segurança.\n",
        "\n",
        "A empresa tem o objetivo de validar a viabilidade dessa feature, e para isso será\n",
        "necessário fazer um MVP para detecção supervisionada desses objetos."
      ],
      "metadata": {
        "id": "ghqOy62amwmH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OBJETIVOS\n",
        "\n",
        "*   Construir ou buscar um dataset contendo imagens de facas, tesouras e outros\n",
        "objetos cortantes em diferentes condições de ângulo e iluminação.\n",
        "*   Anotar o dataset para treinar o modelo supervisionado, incluindo imagens\n",
        "negativas (sem objetos perigosos) para reduzir falsos positivos.\n",
        "*   Treinar o modelo\n",
        "*   Desenvolver um sistema de alertas (pode ser e-mail)"
      ],
      "metadata": {
        "id": "6pv5mLv-mwe0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ENTREGÁVEL\n",
        "\n",
        "*   Documentação detalhando o fluxo utilizado para o desenvolvimento da solução\n",
        "*   Vídeo de até 15 minutos explicando a solução proposta\n",
        "*   Link do github do projeto"
      ],
      "metadata": {
        "id": "GCTuvQpynXB8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##O Trabalho\n",
        "\n",
        "Este script utiliza YOLO para detectar objetos cortantes (facas, machados, tesouras) em vídeos.\n",
        "Além da detecção, ele processa os vídeos para destacar os objetos encontrados e envia um alerta por e-mail caso haja identificação de itens perigosos."
      ],
      "metadata": {
        "id": "mTmoMW7SnbS8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 1: Instalação das bibliotecas necessárias\n",
        "\n",
        "Esta célula instala as bibliotecas necessárias para execução do código.\n",
        "- `opencv-python-headless`: Versão do OpenCV sem suporte a interface gráfica, ideal para execução em servidores ou ambientes headless.\n",
        "- `ultralytics`: Biblioteca que contém a implementação do YOLO (You Only Look Once), utilizada para a detecção de objetos."
      ],
      "metadata": {
        "id": "TDLTYW7Cn1PZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54Pb57Z0PZ7W",
        "outputId": "f1e59764-3f5d-4df2-dc25-c774971a6f41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless) (1.26.4)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.75)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python-headless  # versão headless para evitar problemas de exibição gráfica\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 2: Montagem do Google Drive\n",
        "\n",
        "Esta célula monta o Google Drive no ambiente do Colab, permitindo o acesso a arquivos armazenados nele."
      ],
      "metadata": {
        "id": "-l8b_jfvn-Iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFFxZKmIPh6L",
        "outputId": "b397bf8b-59a6-4ade-a963-c9f20312c5c5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 3: Importação das bibliotecas\n",
        "\n",
        "Importa as bibliotecas necessárias para o funcionamento do sistema:\n",
        "- `os`: Manipulação de arquivos e diretórios.\n",
        "- `cv2`: OpenCV para processamento de vídeo.\n",
        "- `smtplib`: Envio de e-mails via protocolo SMTP.\n",
        "- `datetime`: Obtenção da data e hora atuais.\n",
        "- `ultralytics.YOLO`: Modelo de detecção YOLO.\n",
        "- `email.message.EmailMessage`: Construção de mensagens de e-mail.\n",
        "- `google.colab.files`: Upload de arquivos no Colab."
      ],
      "metadata": {
        "id": "75Y4kTBPoHYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import smtplib\n",
        "from datetime import datetime\n",
        "from ultralytics import YOLO\n",
        "from email.message import EmailMessage\n",
        "from google.colab import files  # Para upload do vídeo"
      ],
      "metadata": {
        "id": "9Vrm5ktWPlsh"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 4: Configuração do e-mail\n",
        "\n",
        "- Define as configurações para envio de e-mails de alerta\n",
        "- Cria um diretório chamado `processed_videos` para armazenar os vídeos após o processamento.\n",
        "Se a pasta já existir, nada será alterado\n",
        "- Carrega o modelo YOLO treinado para detecção de objetos perigosos\n",
        "- Cria um conjunto contendo os nomes dos objetos considerados perigosos para detecção"
      ],
      "metadata": {
        "id": "JQ8bl4W0oT2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração do e-mail\n",
        "SMTP_SERVER = \"smtp.gmail.com\"\n",
        "SMTP_PORT = 587\n",
        "EMAIL_SENDER = \"securytevisionguard@gmail.com\"\n",
        "EMAIL_PASSWORD = \"qihv lyhu ajng gncr\"\n",
        "EMAIL_RECEIVER = \"lincoln.soa@gmail.com\"\n",
        "\n",
        "# Pasta para salvar vídeos processados\n",
        "output_dir = \"processed_videos\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Modelo YOLO para detecção\n",
        "model = YOLO('/content/best.pt')\n",
        "\n",
        "# Lista de objetos perigosos a serem detectados\n",
        "dangerous_objects = {'knife', 'axe', 'scissors'}"
      ],
      "metadata": {
        "id": "Y9sY52nxo1U6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 5: Função para envio de e-mail\n",
        "\n",
        "Define a função `send_email(detected)`, que envia um e-mail caso objetos perigosos tenham sido detectados no vídeo.\n",
        "Se um objeto for encontrado, um e-mail de alerta será enviado ao destinatário."
      ],
      "metadata": {
        "id": "G2ALmTkxpC65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def send_email(detected):\n",
        "    msg = EmailMessage()\n",
        "    msg[\"From\"] = EMAIL_SENDER\n",
        "    msg[\"To\"] = EMAIL_RECEIVER\n",
        "\n",
        "    if detected:\n",
        "        msg[\"Subject\"] = \"⚠️ Objetos Perigosos Detectados no Vídeo Analisado\"\n",
        "        msg.set_content(\"Foram detectados objetos cortantes perigosos no vídeo analisado e o resultado desta análise você pode conferir no diretório: processed_videos\")\n",
        "    else:\n",
        "        print(\"✅ Nenhum Objeto Perigoso Encontrado no Vídeo\")\n",
        "\n",
        "    try:\n",
        "        with smtplib.SMTP(SMTP_SERVER, SMTP_PORT) as server:\n",
        "            server.starttls()\n",
        "            server.login(EMAIL_SENDER, EMAIL_PASSWORD)\n",
        "            server.send_message(msg)\n",
        "        print(\"E-mail enviado com sucesso!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao enviar e-mail: {e}\")"
      ],
      "metadata": {
        "id": "2qxnRC9gW_gd"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 6: Função de processamento de vídeo\n",
        "\n",
        "A função `process_video(video_path)` abre o vídeo, processa cada frame, detecta objetos perigosos e salva o resultado.\n",
        "Se um objeto for identificado, ele será destacado no vídeo e um e-mail será enviado."
      ],
      "metadata": {
        "id": "ZDgP9JkUpFfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_video(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Erro ao abrir o vídeo.\")\n",
        "        return\n",
        "\n",
        "    # Configura o vídeo de saída\n",
        "    video_name = os.path.basename(video_path)\n",
        "    output_video_path = os.path.join(output_dir, f\"processed_{video_name}\")\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    frame_size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, fps, frame_size)\n",
        "\n",
        "    detected_dangerous = False  # Flag para rastrear se objetos perigosos foram encontrados\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        results = model(frame)\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                x1, y1, x2, y2 = box.xyxy[0].numpy()\n",
        "                confidence = box.conf[0]\n",
        "                cls = box.cls[0]\n",
        "                label = model.names[int(cls)]\n",
        "\n",
        "                if label in dangerous_objects:\n",
        "                    detected_dangerous = True\n",
        "                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)\n",
        "                    cv2.putText(frame, f\"{label} {confidence:.2f}\", (int(x1), int(y1) - 10),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "\n",
        "        out.write(frame)  # Salva o frame processado no vídeo de saída\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    print(f\"Vídeo processado salvo em: {output_video_path}\")\n",
        "\n",
        "    # Envia e-mail com a detecção final\n",
        "    send_email(detected_dangerous)"
      ],
      "metadata": {
        "id": "-eRBOoTSP12n"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 7: Definição do vídeo de entrada e processamento\n",
        "\n",
        "Define o caminho do vídeo a ser analisado e executa a função `process_video()` para iniciar a análise."
      ],
      "metadata": {
        "id": "ycH5GnzOpK0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_filename = \"/content/video2.mp4\"\n",
        "\n",
        "print(\"Arquivo de vídeo recebido:\", video_filename)\n",
        "process_video(video_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buCIZDHMdqR-",
        "outputId": "51d565cf-ac5d-4dc0-eb42-2700113a2324"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo de vídeo recebido: /content/video2.mp4\n",
            "\n",
            "0: 384x640 1 knife, 1489.2ms\n",
            "Speed: 3.8ms preprocess, 1489.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 knife, 1225.1ms\n",
            "Speed: 3.2ms preprocess, 1225.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 knife, 904.8ms\n",
            "Speed: 2.5ms preprocess, 904.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 883.7ms\n",
            "Speed: 3.5ms preprocess, 883.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 axe, 882.8ms\n",
            "Speed: 2.4ms preprocess, 882.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 866.1ms\n",
            "Speed: 2.3ms preprocess, 866.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 knife, 879.9ms\n",
            "Speed: 3.1ms preprocess, 879.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 878.0ms\n",
            "Speed: 3.2ms preprocess, 878.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 875.3ms\n",
            "Speed: 3.4ms preprocess, 875.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 891.5ms\n",
            "Speed: 3.1ms preprocess, 891.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 867.7ms\n",
            "Speed: 3.5ms preprocess, 867.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 871.9ms\n",
            "Speed: 3.2ms preprocess, 871.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 987.1ms\n",
            "Speed: 3.1ms preprocess, 987.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 1401.8ms\n",
            "Speed: 3.5ms preprocess, 1401.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 1390.9ms\n",
            "Speed: 5.9ms preprocess, 1390.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 1257.6ms\n",
            "Speed: 3.4ms preprocess, 1257.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 876.4ms\n",
            "Speed: 3.4ms preprocess, 876.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 889.8ms\n",
            "Speed: 2.8ms preprocess, 889.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 873.4ms\n",
            "Speed: 3.0ms preprocess, 873.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 880.5ms\n",
            "Speed: 3.0ms preprocess, 880.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 869.6ms\n",
            "Speed: 3.9ms preprocess, 869.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 885.1ms\n",
            "Speed: 3.0ms preprocess, 885.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 888.6ms\n",
            "Speed: 3.3ms preprocess, 888.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 888.6ms\n",
            "Speed: 3.3ms preprocess, 888.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 883.1ms\n",
            "Speed: 3.1ms preprocess, 883.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 879.0ms\n",
            "Speed: 2.9ms preprocess, 879.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 950.0ms\n",
            "Speed: 3.4ms preprocess, 950.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 1407.7ms\n",
            "Speed: 4.2ms preprocess, 1407.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 1379.5ms\n",
            "Speed: 3.5ms preprocess, 1379.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 1285.2ms\n",
            "Speed: 3.7ms preprocess, 1285.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 876.5ms\n",
            "Speed: 2.7ms preprocess, 876.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 875.5ms\n",
            "Speed: 4.2ms preprocess, 875.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 909.6ms\n",
            "Speed: 3.7ms preprocess, 909.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 881.1ms\n",
            "Speed: 3.3ms preprocess, 881.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 872.2ms\n",
            "Speed: 3.4ms preprocess, 872.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 861.8ms\n",
            "Speed: 3.0ms preprocess, 861.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 870.9ms\n",
            "Speed: 3.0ms preprocess, 870.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 knife, 884.9ms\n",
            "Speed: 3.3ms preprocess, 884.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 knife, 895.7ms\n",
            "Speed: 3.5ms preprocess, 895.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Vídeo processado salvo em: processed_videos/processed_video2.mp4\n",
            "E-mail enviado com sucesso!\n"
          ]
        }
      ]
    }
  ]
}